#+Title: Coordinates & Transforms in 2D
#+Author: Chris Hodapp

* Coordinates & Transforms in 2D

** A slightly boring, laborious example

The Introduction mentioned that all the code this tutorial deals with
is /fragment shaders/ (or pixel shaders) in GLSL.  For our sake, what
that means is that we are dealing with short programs which create
images (and eventually animations) by explicitly giving the color of
every pixel in the image.

This may be a bit different than what you are used to in more general
programming languages.  You are likely used to programs for which, at
any given point in time, variables have a specific value and the
program is executing some specific part of the code.

Fragment shaders deviate from this a bit, and require a bit of a
different mindset.  The way we use them here, they can be thought of
as programs which run simultaneously over every pixel in the image,
and likewise, have variables which take on different values for every
pixel.  (See [[https://en.wikipedia.org/wiki/Stream_processing][Stream processing]] for a little more in-depth information
on this.)

The below code gives a very simple example of this:

#+BEGIN_SRC glsl
uniform vec2 resolution;

void main()
{
  vec2 uv = gl_FragCoord.xy / resolution.xy;
  gl_FragColor = vec4(uv.x, uv.y, 0.0, 1.0);
}
#+END_SRC

Click "Use code", and then go to the "Render" tab.  You should see a
gradient - green at the top left corner, yellow at the top right, red
at the bottom right, black at the bottom left, and colors blended
everywhere between those.

The code might look familiar if you've used something like C, C++, or
Java, but with a few unfamiliar constructs.  =vec2= and =vec4= are
vector types containing 2 elements and 4 elements, respectively (more
on that later).  For now, just treat a =vec2= as a structure with
fields =x= and =y=, and a =vec4= as a structure with fields =r=, =g=,
=b=, and =a=, all of them floating-point values.

=gl_FragCoord= is one of those variables which takes on a different
value for every pixel in the image; the =.xy= provides us a =vec2= of
just the X and Y coordinates of each pixel.  =resolution=, on the
other hand, is a /uniform/ variable - it has the same value over all
pixels.  In this case, it's something the environment provides to tell
us the total number of pixels along X and Y.

=gl_FragCoord.xy / resolution.xy= produces a new =vec2= by dividing
=gl_FragCoord.x= by =resolution.x= and =gl_FragCoord.y= by
=resolution.y=.  Try the code below if you want to verify yourself
that it's the same as splitting them out:

#+BEGIN_SRC glsl
uniform vec2 resolution;

void main()
{
  float u = gl_FragCoord.x / resolution.x;
  float v = gl_FragCoord.y / resolution.y;
  gl_FragColor = vec4(u, v, 0.0, 1.0);
}
#+END_SRC

Thus, the =uv= vector (or =u= and =v= separately above) contains X and
Y coordinates that each have been /normalized/ range from 0 to 1.
Since it's dividing by the total resolution, it works identically at
any resolution (resize the render window and see, or click the
lower-right icon to make it full-screen).  This gives us a normal
/(x,y)/ coordinate plane (or Cartesian plane) where the lower-left
point is (0,0), moving to the right increases the X coordinate, and
moving up increases the Y coordinate - up to the top-right corner
which is (1,1).  This is a fairly standard transformation to see
anytime pixel locations are involved.

Finally, =gl_FragColor= is where we assign the pixel's respective
color into a =vec4= by giving, in order, its red, green, blue, and
alpha channel values (and we ignore alpha here, as it refers to
transparency and doesn't make sense to use here).  Each value is from
0 to 1, and values outside that range are clipped inside of it; try
messing with the values (e.g. replacing =u= with =u * 4.0=) to verify
this.

The result, then, is that we've assigned the red channel of each pixel
to its X coordinate, and the green channel to the Y coordinate.  The
blue channel was just left at 0.  Thus, at the very lower-left, we'd
expect to see black (red and green are both 0 because X and Y are
zero), and moving up to the top-right, we'd expect to see yellow (red
and green are both at their maximum of 1).

** What can this actually do?

You may be complaining that a colored gradient is a rather
uninteresting thing to draw, and it is.  However, with some additional
math, this method of creating graphics is remarkably flexible.

First off, though, we must be able to create some basic shapes and
constructs to demonstrate things.  We've already shown how the
computation of =uv= above can create simple color gradients - but
color gradients by their inherent fuzziness make it difficult to show
any sort of sharp details or well-defined shapes.

So, consider the below code.  The =uv.x= line isn't especially
important, but it will appear again and again, and it is there to
correct the [[https://en.wikipedia.org/wiki/Aspect_ratio_%2528image%2529][aspect ratio]] of the image.  In our case, all it means is
that =uv.x= will be scaled so that a given step in =uv.x= is the same
distance as in =uv.y=, and our shapes aren't squashed.

#+BEGIN_SRC glsl
uniform vec2 resolution;
float count = 10.0;

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    vec2 uv_mod = mod(uv * grid, 1.0);
    
    gl_FragColor = vec4(uv_mod.x, uv_mod.y, 0, 1.0);
}
#+END_SRC

The important line is the definition of =uv_mod=: we've scaled up =uv=
by a certain amount in both X and Y, and then used [[https://en.wikipedia.org/wiki/Modulo_operation][modulo]] to turn it
to a repeating pattern again in X and Y - across some distance, it
rises from 0 to 1, and then goes back to 0.

You should be able to see a sort of grid pattern emerging, and playing
with the value of =count=, or changing the =1.0= in =mod(..., 1.0)= to
something else, should produce some effects that make sense.  However,
if you look, you'll see it's still just a bunch of smaller gradients.
Try looking just at =uv_mod.x= or just =uv_mod.y= (i.e. change
=gl_FragColor= so that the red, green, and blue channel are all
=uv_mod.x=, and then so they all are =uv_mod.y=).

Now consider: How could we turn this into a grid with sharp lines,
instead of gradients?  Try to make sense of the below, and change
values like =thickness= to something else:

#+BEGIN_SRC glsl
uniform vec2 resolution;
float count = 10.0;
float thickness = 0.05;

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    vec2 uv_mod = mod(uv * count, 1.0);
    float x1 = uv_mod.x < thickness ? 1.0 : 0.0;
    float y1 = uv_mod.y < thickness ? 1.0 : 0.0;
    
    gl_FragColor = vec4(x1, y1, 0, 1.0);
}
#+END_SRC

This is a fairly small change from the previous code.  If you're not
familiar, =uv_mod= is now defined using the [[https://en.wikipedia.org/wiki/%253F:#C][ternary operator]] that is
commonly used in C.  In simple, it has forced the darker parts (see
=thickness=) to be uniformly light, and the parts other than that to
be uniformly black.  However, the X and Y grid lines are still
separated out, and we may simply add them together to give white grid
lines:

#+BEGIN_SRC glsl
uniform vec2 resolution;
float count = 10.0;
float thickness = 0.05;

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    vec2 uv_mod = mod(uv * count, 1.0);
    float x1 = uv_mod.x < thickness ? 1.0 : 0.0;
    float y1 = uv_mod.y < thickness ? 1.0 : 0.0;
    float grey = x1 + y1;
    
    gl_FragColor = vec4(grey, grey, grey, 1.0);
}
#+END_SRC

** Implicit functions

Perhaps it wasn't obvious why this is significant, but to try to
explain it further: We just used an [[https://en.wikipedia.org/wiki/Implicit_function][implicit function]] to draw lines.
Rather than drawing lines by iteratively walking along pixel
coordinates and darkening certain ones according to a line's formula,
we started with a formula that was something like:

\begin{equation}
   f(x,y)=I(x\mod C)+I(y\mod C) \mathrm{ where}\\
   I(a) = \begin{cases}
   a < \epsilon & : 1\\
   a \ge \epsilon & : 0
   \end{cases}
\end{equation}

and then evaluated this over every pixel, using $C$ as basically
=count= and $\epsilon$ as =thickness=.  We've taken some liberties, in
that we're comparing with $\epsilon$ rather than 0, but that is due to
using floating point and a discrete number of pixels. If we express
this function explicitly:

#+BEGIN_SRC glsl
uniform vec2 resolution;

float grid(vec2 xy, float thickness, float count)
{
    vec2 uv_mod = mod(xy * count, 1.0);
    float x1 = uv_mod.x < thickness ? 1.0 : 0.0;
    float y1 = uv_mod.y < thickness ? 1.0 : 0.0;
    return x1 + y1;
}

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    float grey = grid(uv, 0.05, 10.0);
    
    gl_FragColor = vec4(grey, grey, grey, 1.0);
}
#+END_SRC

Put another way, we just drew [[https://en.wikipedia.org/wiki/Contour_line][isolines]] of that function.

More about this implicit functions will follow later.  For now, we
just use it to create a grid to help illustrate some transformations.
Below is one that may be familiar: It converts the coordinates we're
using already - rectangular, or Cartesian, coordinates in =uv= - to
[[https://en.wikipedia.org/wiki/Polar_coordinate_system][polar coordinates]].  =uv= is also rescaled and moved so that the center
is (0,0).  Then, we use polar rather than rectangular coordinates to
draw this grid.

#+BEGIN_SRC glsl
uniform vec2 resolution;
const float PI = 3.14159265359;

float grid(vec2 xy, float thickness, float count)
{
    vec2 uv_mod = mod(xy * count, 1.0);
    float x1 = uv_mod.x < thickness ? 1.0 : 0.0;
    float y1 = uv_mod.y < thickness ? 1.0 : 0.0;
    return x1 + y1;
}

vec2 rect2polar(vec2 xy)
{
    vec2 polar = vec2(length(xy), atan(xy.y, xy.x));
    return polar;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    vec2 polar = rect2polar(uv);
    polar.y = polar.y / PI;
    float grey = grid(polar, 0.05, 10.0);
    
    gl_FragColor = vec4(grey, grey, grey, 1.0);
}
#+END_SRC

Note that, despite the notation, fields =x= and =y= of =polar= now
stand for radius and angle, not X and Y coordinates.

We started with a grid made of equally-sized squares.  The above
should give some intuitive sense of how the conversion to polar
coordinates transformed space: The grid "squares" are now
differently-sized sections of a circle. 

** Animation & Mouse Input

Up to this point, we've just been rendering images that don't change
over time or in response to any input (aside from you editing the
code).  The below code makes a couple modifications to the last
example to change this:

#+BEGIN_SRC glsl
uniform vec2 resolution;
const float PI = 3.14159265359;
uniform vec4 mouse;
uniform float time;

float grid(vec2 xy, float thickness, float count)
{
    vec2 uv_mod = mod(xy * count, 1.0);
    float x1 = uv_mod.x < thickness ? 1.0 : 0.0;
    float y1 = uv_mod.y < thickness ? 1.0 : 0.0;
    return x1 + y1;
}

vec2 rect2polar(vec2 xy)
{
    vec2 polar = vec2(sqrt(xy.x * xy.x + xy.y * xy.y), atan(xy.y, xy.x));
    return polar;
}

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    vec2 polar = rect2polar(uv - m);
    // Radius:
    polar.x = polar.x - time / 10.0;
    // Angle:
    polar.y = (polar.y / PI) + time / 8.0;
    float grey = grid(polar, 0.05, 10.0);
    
    gl_FragColor = vec4(grey, grey, grey, 1.0);
}
#+END_SRC

To see the render react to input, click or drag in the render window.
The environment provides two new variables - =mouse= and =time= -
which give, respectively, the mouse location and a time value (which
simply counts up in seconds).  (=mouse=, for whatever reason, uses a
different coordinate system than the rest of the image, so above we
remedy this when we compute =m= and then we do the same transformation
to normalize this mouse position as we do each pixel coordinate.)

There are two buttons at the bottom center of the render window which
let you stop animation completely, and pause or resume it.  It will
continue to react to mouse input even when paused or stopped.

In the last example, the center of the image was (0,0) (in both
rectangular and polar coordinates, incidentally); in this one, note
that by subtracting the mouse position, wherever you click is the new
origin.

See the changes to =polar.x= and =polar.y= for the source of the
animation; change how =time= is used (adding vs. subtracting, and
dividing by larger and smaller numbers), and it should make sense how
this works.

** Control Inputs

# I think I need this interactivity before I can proceed

** Textures?

# Goal: To quickly get into color functions that are more interesting
# and better for illustrating the nonlinear warps.  From here, I can
# get into weird spiral things, and eventually into Perlin noise /
# simplex noise.

# Tying things together: This is useful in its own right (link to
# Conal's blog and anything else I know of), but also is useful as a
# way to apply textures to objects in conjunction with more
# complicated shading (link to Perlin's paper, An image synthesizer).
# Mention this notion of treating textures like a 3D liquid that the
# object is dipped in, versus something 2D that is mapped to an
# object - though, that is done too (link to UV texturing).

** Transformations

We've used various kinds of transformation on the image so far, but
they haven't really been explained or made explicit.

*** Scaling

*** Translation

*** Rotation

*** Shearing

*** Vectors & Matrices
# Homogeneous coordinates?
# Composition
# Inverses

# Does it even make sense to explain these here, or wait until 3D?  I
# feel like it's just drudgery to go into too much detail explaining
# them here - but it may also be too much too fast to wait until 3D to
# try to explain them.
#
# However, I have no particular reason to explain them *before* the texturing stuff.

# Part of the point is to show that WebGL has built-in support for
# some of these matters, I suppose.

# Misc:
# WebGL 'mix' function - get softer edges on lines?

