#+Title: 3D Rendering
#+Author: Chris Hodapp

* 3D Rendering

In the last section, we dealt with a class of functions which mapped
2D space (i.e. a pixel location) to color values.  In this section, we
generalize this a bit, and deal with functions that map 3D space to
something.

First, though, consider a (far-fetched) thought experiment.  Suppose
you're outside and you need to trace out some strange geographical
boundary - maybe an irregular, invisible property line.  For whatever
reason, you don't even have a map.  What you do have is a precise but
rather strange GPS device... and all it can do is tell you, whenever
you need, the shortest distance you could move in order to reach the
nearest part of that boundary.  It doesn't tell you which direction.
If it tells you "21 feet", all it means is that in some direction, the
boundary is exactly 21 feet away, and it's not closer than that in any
other direction.

Assume you have some other basic implements, like a tape measure and a
can of spray paint, and assume that you at least know you're starting
somewhere inside this boundary.  Now, how could you go about finding
and marking this boundary (or something fairly close to it)?

There are probably many different answers, but here is one method to
consider:

1. Mark your starting point on the ground.
2. Pick any direction.
3. Get the nearest-distance measurement from the GPS.
4. Walk in a straight line in the chosen direction until you've
   covered the distance the GPS told you.
5. Go back to step 3, using the same direction. Once the GPS gives
   distance measurements that are very small (e.g. one inch), stop.
6. Wherever you are, make a marking on the ground.
7. Return to your starting point.
8. Pick a new direction, rotated very slightly from the last time
   (e.g. just 1/2 degree clockwise).
9. Repeat step 3.  Once you've returned to your starting direction,
   stop.

This is very pain-staking and tedious - but the end result is that
you've marked off the entire boundary, at 1/2 degree increments, to
within an inch. (It's possible you'll miss spots, particularly if it's
a very weird boundary - but you can remedy this by taking more samples
and repeating the process, sometimes from different spots.)

To put it in more technical terms: You just traced out the *distance
surface* that a *distance function* (or a distance field) described
implicitly. If this sounds like it's related to the mention of
*isolines* in the last section, it's because it is.

** Distance Functions

In that thought experiment, the hypothetical GPS was providing a
*distance function* which maps every point in 2D space to a
nearest-distance value.  Put another way, that distance function is
providing, for any given point, the radius of the largest possible
circle (centered at that point) which does *not* intersect that
boundary.

This works identically in 3 dimensions.  The only change is that it is
giving the radius of the largest sphere, not the largest circle, and
it is implicitly describing an entire 3D surface, not just a 2D
boundary.

# TODO: Where does the below go?

Interestingly enough, the above method still works if the GPS behaves
a little more strangely: it doesn't need to tell you the exact
distance; it could simply tell you some (non-zero) distance for which
you're guaranteed *not* to hit the boundary in any direction.

** Sphere Tracing

Using a very similar process as in the thought experiment above, this
distance function can be used to trace out 3D surfaces seen from some
point - in other words, to render them in 3D.  This can be done with
*sphere tracing*, an algorithm that performs a very similar process
pixel-by-pixel.  It is similar to [[https://en.wikipedia.org/wiki/Ray_tracing_(graphics)][ray tracing]]; it is technically a
method of ray marching.

Below is an example of rendering a sphere in 3D this way.  Don't worry
too much about =main()=; this code is just there to set up the
renderer, which is a little more complicated in 3D.  Focus on
=distance()= - this is the distance function that is actually being
rendered, and it's called indirectly via =render=.

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": 0,
       "max": 10,
       "name": "radius",
       "GUIName": "Radius"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float radius;

float distance(in vec3 pos)
{
    return length(pos) - radius;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

You can drag the view around with the mouse, and adjust the sphere's
radius with the slider.  You're now looking at a 3D coordinate system,
not a 2D one; the X and Z axes are the ground (so to speak), and the Y
axis is up.

If you look more closely at =distance= you might note that the
distance function will return negative values *inside* the sphere.
This is intentional; we now have a [[https://en.wikipedia.org/wiki/Signed_distance_function][signed distance function]].  It's a
fairly small change: The 3D surface must have a clear inside and
outside, and the signed distance function returns a positive number
for any point *outside* that surface and a negative number for any
point *inside* that surface.  It's otherwise the same.

Try to make sense of why this produces a sphere.

** Blah blah blah

If $a^2=b$ and \( b=2 \), then the solution must be
either $$ a=+\sqrt{2} $$ or \[ a=-\sqrt{2} \].

\begin{equation}
x=\sqrt{b}
\end{equation}

** Repeated cubes 1

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0.1,
       "min": -5,
       "max": 5,
       "name": "freq",
       "GUIName": "Freq"
   },
   {
       "type": "float",
       "value": 0.1,
       "min": -1,
       "max": 1,
       "name": "freq2",
       "GUIName": "Freq2"
   }   
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

uniform float freq;
uniform float freq2;

float distance(in vec3 pos)
{
    vec3 pos_ = vec3(mod(pos.x, 2.0) - 1.0, pos.y, mod(pos.z, 2.0) - 1.0);
    float ca = cos(freq * pos_.y);
    float sa = sin(freq * pos_.y);
    vec3 pos2 = vec3(pos_.x * ca - pos_.z * sa, pos_.y, pos_.x * sa + pos_.z * ca);
    float ca2 = cos(freq2 * pos2.z);
    float sa2 = sin(freq2 * pos2.z);
    vec3 pos3 = vec3(pos2.x * ca2 - pos2.y * sa2, pos2.x * sa2 + pos2.y * ca2, pos2.z);
    float res = min(sdPlane(pos),
                    udRoundBox(pos3-vec3(0.0, 0.5, 0.0), vec3(0.5), 0.05));
    return res;
}

void main()
{
    vec2 mo = mouse.xy/resolution.xy;
	float time = 15.0 + time;
    
    vec3 tot = vec3(0.0);
    vec2 p = (-resolution.xy + 2.0*gl_FragCoord.xy)/resolution.y;
    // Camera location:
    vec3 ro = vec3(-0.5+3.5*cos(0.1*time + 6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 4.0*sin(0.1*time + 6.0*mo.x));
    // Camera target:
    vec3 ta = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation
    mat3 ca = setCamera(ro, ta, 0.0);
    
    // ray direction
    vec3 rd = ca * normalize(vec3(p.xy, 2.0));

    // render	
    vec3 col = render(ro, rd);

    // gamma
    col = pow(col, vec3(0.4545));
    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC


** Repeated cubes 2

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 2,
       "min": 1,
       "max": 10,
       "name": "dx",
       "GUIName": "dx"
   },
   {
       "type": "float",
       "value": 2,
       "min": 1,
       "max": 10,
       "name": "dz",
       "GUIName": "dz"
   }   
]
END */

#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

uniform float dx;
uniform float dz;

float distance(in vec3 pos)
{
    float ca_d = cos(0.05 * length(pos) + time*0.1);
    float sa_d = sin(0.05 * length(pos) + time*0.1);
    vec3 pos_ = pos;
    pos_ = vec3(pos_.x * ca_d - pos_.y * sa_d, pos_.x * sa_d + pos_.y * ca_d, pos_.z);
    
    float ca_d2 = cos(0.05 * length(pos) + time*0.2);
    float sa_d2 = sin(0.05 * length(pos) + time*0.2);
    //pos_ = vec3(pos_.x, pos_.y * ca_d2 - pos_.z * sa_d2, pos_.y * sa_d2 + pos_.z * ca_d2);

    pos_ = vec3(mod(pos_.x, dx) - dx/2.0, pos_.y, mod(pos_.z, dz) - dz/2.0);
    /*
    float ca = cos(freq * pos_.y);
    float sa = sin(freq * pos_.y);
    vec3 pos2 = vec3(pos_.x * ca - pos_.z * sa, pos_.y, pos_.x * sa + pos_.z * ca);
    float ca2 = cos(freq2 * pos2.z);
    float sa2 = sin(freq2 * pos2.z);
    vec3 pos3 = vec3(pos2.x * ca2 - pos2.y * sa2, pos2.x * sa2 + pos2.y * ca2, pos2.z);*/
    float res = udRoundBox(pos_-vec3(0.0, 0.5, 0.0), vec3(0.5), 0.05);
    return res;
}

void main()
{
    vec2 mo = mouse.xy/resolution.xy;
    
    vec3 tot = vec3(0.0);
    vec2 p = (-resolution.xy + 2.0*gl_FragCoord.xy)/resolution.y;
    // Camera location:
    vec3 ro = vec3(-0.5+3.5*cos(0.1*time + 6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 4.0*sin(0.1*time + 6.0*mo.x));
    // Camera target:
    vec3 ta = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation
    mat3 ca = setCamera(ro, ta, 0.0);
    
    // ray direction
    vec3 rd = ca * normalize(vec3(p.xy, 2.0));

    // render	
    vec3 col = render(ro, rd);

    // gamma
    col = pow(col, vec3(0.4545));
    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

** Repeated cubes 3

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 2,
       "min": 1,
       "max": 10,
       "name": "dist",
       "GUIName": "Dist"
   }   
]
END */

#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

uniform float dist;

float distance(in vec3 pos)
{
    vec3 pos_ = mod(pos, dist) - dist/2.0;
    float res = sdBox(pos_, vec3(0.5));
    return res;
}

void main()
{
    vec2 mo = mouse.xy/resolution.xy;
    
    vec3 tot = vec3(0.0);
    vec2 p = (-resolution.xy + 2.0*gl_FragCoord.xy)/resolution.y;
    // Camera location:
    vec3 ro = vec3(-0.5+3.5*cos(0.1*time + 6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 4.0*sin(0.1*time + 6.0*mo.x));
    // Camera target:
    vec3 ta = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation
    mat3 ca = setCamera(ro, ta, 0.0);
    
    // ray direction
    vec3 rd = ca * normalize(vec3(p.xy, 2.0));

    // render	
    vec3 col = render(ro, rd);

    // gamma
    col = pow(col, vec3(0.4545));
    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

** Distance Bounds & Distance Fields

*** Why a sphere tracer?

** Transformations

# See "Programming in 3 Dimensions"

*** Scaling

*** Translation

*** Rotation

*** Shearing

*** Vectors & Matrices
# Homogeneous coordinates?
# Composition
# Inverses

** Constructive Solid Geometry

** Domain Warping

** Domain Repetition

** Summary

This concludes the tutorial - at least, until I write more.

I mentioned that distance fields were a sort of extension of what we
looked at in the last section - particularly, of what we can do with
functions that map points in space to something (color, or a distance
bound, for instance).  Another application of this same principle can
be found in the [[https://www.cs.jhu.edu/~subodh/458/p253-perlin.pdf][Hypertexture]] approach of Perlin and Hoffert - in which
a function maps points in 3D space to *density* at that point.

3D rendering is a subject both broad and deep, and this tutorial
covers just a narrow part of one aspect of them.  The next section
gives a handful of references that may be good starting points.

# TODO: Mind the goal of this, which is not graphics but math.
