#+Title: 3D Rendering
#+Author: Chris Hodapp

* 3D Rendering

If $a^2=b$ and \( b=2 \), then the solution must be
either $$ a=+\sqrt{2} $$ or \[ a=-\sqrt{2} \].

\begin{equation}
x=\sqrt{b}
\end{equation}

** Sphere example

#+BEGIN_SRC glsl
uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

// camera attributes
// cameraDirection and cameraUp MUST be normalized
// (ie. their length must be equal to 1)
const vec3 cameraPosition_ = vec3(0.0, 0.0, 10.0);
const vec3 cameraDirection = vec3(0.0, 0.0, -1.0);
const vec3 cameraUp = vec3(0.0, 1.0, 0.0);

// ray computation vars
const float PI = 3.14159265359;
const float fov = 50.0;
const float fovx = PI * fov / 360.0;
float fovy = fovx * resolution.y/resolution.x;
float ulen = tan(fovx);
float vlen = tan(fovy);

float distanceToNearestSurface(vec3 p){
    return length(p) - 1.0;
}

bool intersectsWithWorld(vec3 p, vec3 dir){
  float dist = 0.0;
  for(int i = 0; i < 20; i++){
    float nearest = distanceToNearestSurface(p + dir*dist);
    if(nearest < 0.01) return true;
    dist += nearest;
  }
  return false;
}

void main()
{
    vec2 uv = gl_FragCoord.xy/resolution.xy;
  
    // generate the ray for this pixel
    vec2 camUV = uv*2.0 - vec2(1.0, 1.0);
    vec3 nright = normalize(cross(cameraUp, cameraDirection));
    vec3 pixel = cameraPosition_ + cameraDirection +
                 nright*camUV.x*ulen + cameraUp*camUV.y*vlen;
    vec3 rayDirection = normalize(pixel - cameraPosition_);
    
    float collidedWithWorld = 0.0;
    if(intersectsWithWorld(cameraPosition_, rayDirection))
        collidedWithWorld = 1.0;
    
    gl_FragColor = vec4(collidedWithWorld, 0.0, 0.0, 1.0);
}
#+END_SRC

** Distance Bounds & Distance Fields

*** Why a sphere tracer?

** Transformations

# See "Programming in 3 Dimensions"

*** Scaling

*** Translation

*** Rotation

*** Shearing

*** Vectors & Matrices
# Homogeneous coordinates?
# Composition
# Inverses

** Constructive Solid Geometry

** Domain Warping

** Domain Repetition

** Summary

This concludes the tutorial - at least, until I write more.

I mentioned that distance fields were a sort of extension of what we
looked at in the last section - particularly, of what we can do with
functions that map points in space to something (color, or a distance
bound, for instance).  Another application of this same principle can
be found in the [[https://www.cs.jhu.edu/~subodh/458/p253-perlin.pdf][Hypertexture]] approach of Perlin and Hoffert - in which
a function maps points in 3D space to *density* at that point.

3D rendering is a subject both broad and deep, and this tutorial
covers just a narrow part of one aspect of them.  The next section
gives a handful of references that may be good starting points.

# TODO: Mind the goal of this, which is not graphics but math.
