#+Title: 3D Rendering
#+Author: Chris Hodapp

* 3D Rendering

In the last chapter, we dealt with a class of functions which mapped
2D space (i.e. a pixel location) to color values.  In this chapter, we
generalize this a bit, and deal with functions that map 3D space to
something.

First, though, consider a (far-fetched) thought experiment.  Suppose
you're outside and you need to trace out some strange geographical
boundary - maybe an irregular, invisible property line.  For whatever
reason, you don't even have a map.  What you do have is a precise but
rather strange GPS device... and all it can do is tell you, whenever
you need, the shortest distance you could move in order to reach the
nearest part of that boundary.  It doesn't tell you which direction.
If it tells you "21 feet", all it means is that in some direction, the
boundary is exactly 21 feet away, and it's not closer than that in any
other direction.

Assume you have some other basic implements, like a tape measure and a
can of spray paint, and assume that you at least know you're starting
somewhere inside this boundary.  Now, how could you go about finding
and marking this boundary (or something fairly close to it)?

There are probably many different answers, but here is one method to
consider:

1. Mark your starting point on the ground.
2. Pick any direction.
3. Get the nearest-distance measurement from the GPS.
4. Walk in a straight line in the chosen direction until you've
   covered the distance the GPS told you.
5. Go back to step 3, using the same direction. Once the GPS gives
   distance measurements that are very small (e.g. one inch), stop.
6. Wherever you are, make a marking on the ground.
7. Return to your starting point.
8. Pick a new direction, rotated very slightly from the last time
   (e.g. just 1/2 degree clockwise).
9. Repeat step 3.  Once you've returned to your starting direction,
   stop.

This is very pain-staking and tedious - but the end result is that
you've marked off the entire boundary, at 1/2 degree increments, to
within an inch. (It's possible you'll miss spots, particularly if it's
a very weird boundary - but you can remedy this by taking more samples
and repeating the process, sometimes from different spots.)

To put it in more technical terms: You just traced out the *distance
surface* that a *distance function* (or a distance field) described
implicitly. If this sounds like it's related to the mention of
*isolines* in the last chapter, it's because it is.

** Distance Functions

In that thought experiment, the hypothetical GPS was providing a
*distance function* which maps every point in 2D space to a
nearest-distance value.  Put another way, that distance function is
providing, for any given point, the radius of the largest possible
circle (centered at that point) which does *not* intersect that
boundary.

This works identically in 3 dimensions.  The only change is that it is
giving the radius of the largest sphere, not the largest circle, and
it is implicitly describing an entire 3D surface, not just a 2D
boundary.

# TODO: Where does the below go?

Interestingly enough, the above method still works if the GPS behaves
a little more strangely: it doesn't need to tell you the exact
distance; it could simply tell you some (non-zero) distance for which
you're guaranteed *not* to hit the boundary in any direction.

** Sphere Tracing

Using a very similar process as in the thought experiment above, this
distance function can be used to trace out 3D surfaces seen from some
point - in other words, to render them in 3D.  This can be done with
*sphere tracing*, an algorithm that performs a very similar process
pixel-by-pixel.  It is similar to [[https://en.wikipedia.org/wiki/Ray_tracing_(graphics)][ray tracing]]; it is technically a
method of ray marching.

Below is an example of rendering a cube in 3D this way.  Don't worry
too much about =main()=; this code is just there to set up the
renderer, which is a little more complicated in 3D.  Focus on
=distance()= - this is the distance function that is actually being
rendered, and it's called indirectly via =render=.

#+BEGIN_SRC glsl
/* PARAMETERS
[
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;

float distance(in vec3 pos)
{
    return length(max(abs(pos) - 1.0, 0.0));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

You can drag the view around with the mouse.  You're now looking at a
3D coordinate system, not a 2D one; the X and Z axes are the ground
(so to speak), and the Y axis is up.  In this case the mouse is
dragging around the camera's position, not the coordinate system
itself.

To explain why =distance= works, it may help to expand the rather
terse equation a little; =max= and =abs= are both element-wise, while
=length= is over the entire vector.  If $d(p)$ stands for
=distance(pos)=:

\begin{equation}
d(p)=\sqrt{\max(|p_x|-1,0)^2+\max(|p_y|-1,0)^2+\max(|p_z|-1,0)^2}
\end{equation}

Mentally try a few values of $p_x$ in $\max(|p_x|-1,0)$.  Note that
for $-1 \leq p_x \leq 1$, it is zero, while picking a value of
$p_x<-1$ gives the distance in the $x$ axis to -1 and picking a value
of $p_x>1$ gives the distance in the $x$ axis to 1.  It behaves
identically for $p_y$ and the $y$ axis, and $p_z$ and the $z$ axis.
The final result is just applying the distance formula to these three
values, thus giving the total distance from the region $-1 \leq p_x
\leq 1$, $-1 \leq p_y \leq 1$, and $-1 \leq p_z \leq 1$ - which is a
cube of sidelength 2, centered at $(0,0,0)$.

** Transformations

[[./02_2D_Coordinates.org][Chapter 2]] discussed how we could change something by transforming the
2D coordinate space it's in.  We can do that identically with the 3D
coordinate space here.  See the example below, and note that the only
thing we've done is replace $d(p)$ with $\frac{d(sp)}{s}$, where $s$ is
a new parameter just added.

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": 0,
       "max": 5,
       "name": "s",
       "GUIName": "s"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float s;

float distance(in vec3 pos)
{
    return length(max(abs(pos * s) - 1.0, 0.0)) / s;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

Adjust the parameter's value, and the effect may be the inverse of
what you would expect.  To make sense of this, consider that by
multiplying =pos= by a value > 1, you are scaling up the entire
space - but the cube still has a constant sidelength of 2.  (Dividing
the length by $s$ is a correction that is only needed because
=distance()= returns a length that must be in our "original" space,
not our new scaled space - but scaling changes this length.)

Predictably, some other basic motions are easy too.  The code below
adds 3 parameters, $tx$, $ty$, and $tz$, and subtracts these from the
location before applying the scaling of the last step:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": 0,
       "max": 5,
       "name": "s",
       "GUIName": "s"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tx",
       "GUIName": "tx"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "ty",
       "GUIName": "ty"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tz",
       "GUIName": "tz"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float s;
uniform float tx;
uniform float ty;
uniform float tz;

float distance(in vec3 pos)
{
    vec3 pos2 = pos - vec3(tx, ty, tz);
    return length(max(abs(pos2 * s).xyz - 1.0, 0.0)) / s;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

Similar intuition applies here: In subtracting $(t_x, t_y, t_z)$ we
are shifting (or translating) the entire space so that the coordinates
$(t_x, t_y, t_z)$ are the new origin of the space.  Note that the
scaling is done *after* the translation; the order matters here.
Scale and translate in the opposite order to see why.

** Matrices

While scaling and translating are simple enough operations to do
manually with multiplications and subtractions, other transformations
can become unruly when expressed this way.

Fortunately, WebGL and GLSL provide support for matrices.  The
following matrix will rotate around the $x$ axis, for instance:

\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  0 & \cos\theta & -\sin\theta & 0 \\
  0 & \sin\theta & \cos\theta & 0 \\
  0 & 0 & 0 & 1
\end{bmatrix}

WebGL treats the =vec4= like a 4x1 matrix (i.e. a column vector), and
so the =pos_h * rot= in the below code is computed as:

\begin{equation}
\begin{bmatrix}
  p_x \\ p_y \\ p_z \\ 1
\end{bmatrix}
\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  0 & \cos\theta & -\sin\theta & 0 \\
  0 & \sin\theta & \cos\theta & 0 \\
  0 & 0 & 0 & 1
\end{bmatrix} = 
\begin{bmatrix}
  p_x \\ p_y\cos\theta - p_z\sin\theta \\ p_y\sin\theta + p_z\cos\theta \\ 1
\end{bmatrix}
\end{equation}

The below code uses this (note that we multiply the position by the
matrix). 

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "rx",
       "GUIName": "rx"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float rx;

float distance(in vec3 pos)
{
    vec4 pos_h = vec4(pos, 1.0);
    mat4 rot = mat4(1, 0,        0,       0,
                    0, cos(rx), -sin(rx), 0,
                    0, sin(rx),  cos(rx), 0,
                    0, 0,        0,       1);
    return length(max(abs(pos_h * rot) - 1.0, 0.0));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

We have to turn the =vec3= position into a =vec4= and then use =.xyz=
to return it to a =vec3= for reasons that will be explained shortly.

Of course, we can express the scale as a transformation matrix as
well:

\begin{bmatrix}
  s & 0 & 0 & 0 \\
  0 & s & 0 & 0 \\
  0 & 0 & s & 0 \\
  0 & 0 & 0 & 1
\end{bmatrix}

And the translation:

\begin{bmatrix}
  1 & 0 & 0 & -t_x \\
  0 & 1 & 0 & -t_y \\
  0 & 0 & 1 & -t_z \\
  0 & 0 & 0 & 1
\end{bmatrix}

This is used below. They're purposely chained in a particular order:
the position is first translated (translation is done in the
"original" space), then everything is scaled (scaling is relative to
the new, translated origin), then everything is rotated (again,
relative to the new, translated origin).

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": 0,
       "max": 5,
       "name": "s",
       "GUIName": "s"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tx",
       "GUIName": "tx"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "ty",
       "GUIName": "ty"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tz",
       "GUIName": "tz"
   },
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "rx",
       "GUIName": "rx"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float s;
uniform float tx;
uniform float ty;
uniform float tz;
uniform float rx;

float distance(in vec3 pos)
{
    vec4 pos_h = vec4(pos, 1.0);
    mat4 rot = mat4(1, 0,        0,       0,
                    0, cos(rx), -sin(rx), 0,
                    0, sin(rx),  cos(rx), 0,
                    0, 0,        0,       1);
    mat4 trans = mat4(1, 0, 0, -tx,
                      0, 1, 0, -ty,
                      0, 0, 1, -tz,
                      0, 0, 0, 1);
    mat4 scale = mat4(s, 0, 0, 0,
                      0, s, 0, 0,
                      0, 0, s, 0,
                      0, 0, 0, 1);
    return length(max(abs(pos_h * trans * scale * rot).xyz - 1.0, 0.0)) / s;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

This looks like a lot of extra notation, but part of the point comes
about because a series of matrix multiplications like $pTSR_x$ - like
we are doing above for position $p$, translation matrix $T$, scaling
matrix $S$, and rotation matrix $R_x$ - can be rewritten like
$p(TSR_x)$, that is, the three transformation matrices can be
multiplied into a single 4x4 matrix.  This is trivial to do in the
code (and the below should render completely identically):

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": 0,
       "max": 5,
       "name": "s",
       "GUIName": "s"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tx",
       "GUIName": "tx"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "ty",
       "GUIName": "ty"
   },
   {
       "type": "float",
       "value": 0,
       "min": -5,
       "max": 5,
       "name": "tz",
       "GUIName": "tz"
   },
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "rx",
       "GUIName": "rx"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float s;
uniform float tx;
uniform float ty;
uniform float tz;
uniform float rx;

float distance(in vec3 pos)
{
    vec4 pos_h = vec4(pos, 1.0);
    mat4 rot = mat4(1, 0,        0,       0,
                    0, cos(rx), -sin(rx), 0,
                    0, sin(rx),  cos(rx), 0,
                    0, 0,        0,       1);
    mat4 trans = mat4(1, 0, 0, -tx,
                      0, 1, 0, -ty,
                      0, 0, 1, -tz,
                      0, 0, 0, 1);
    mat4 scale = mat4(s, 0, 0, 0,
                      0, s, 0, 0,
                      0, 0, s, 0,
                      0, 0, 0, 1);
    mat4 t = trans * scale * rot;
    return length(max(abs(pos_h * t).xyz - 1.0, 0.0)) / s;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

If you recall the part in chapter 2 on composition of functions, we
are doing exactly the same thing here.  It just happens that the
functions we're composing are mostly matrix multiplications, and
matrix multiplications behave in some helpful ways (e.g. they are
[[https://en.wikipedia.org/wiki/Matrix_multiplication#Properties_of_the_matrix_product_.28any_number_of_matrices_in_the_product.29][associative]]).

** Homogeneous coordinates

It may seem a bit strange that we are working with a 3-element vector,
adding in a 4th element (which is always 1), multiplying this by a 4x4
matrix, and then discarding the 4th element.  With scaling and
rotating (and a few other things), this isn't actually necessary.  We
have used this 3x3 matrix for rotating, and multiplied a =vec3= by it:

\begin{bmatrix}
  1 & 0 & 0 \\
  0 & \cos\theta & -\sin\theta \\
  0 & \sin\theta & \cos\theta \\
\end{bmatrix}

One benefit of this form is that we can interpret it as a [[https://en.wikipedia.org/wiki/Change_of_basis][change of
basis]] matrix.  If our *basis* here is three unit vectors,
$\hat{x}=(1,0,0)$, $\hat{y}=(0,1,0)$, $\hat{z}=(0,0,1)$ (which are
just the $x$, $y$ and $z$ axis), we can look at the above 3x3 matrix,
or any other 3x3 transformation matrix, as three new vectors, one
for each row of the matrix:

\begin{bmatrix}
  \hat{x}' \\ \hat{y}' \\ \hat{z}'
\end{bmatrix}

where $\hat{x}'$ is the result of transforming $\hat{x}$, $\hat{y}'$
the result of transforming $\hat{y}$, and $\hat{z}'$ the result of
transforming $\hat{z}$.  In other words, that matrix contains our
"new" $x$ axis, $y$ axis, and $z$ axis.  This makes some intuitive
sense if we look at the matrix above which rotates around the $x$ axis
by $\theta$: the $x$ axis stays untouched, but the $y$ and $z$ axis
rotate.  Similar intuition applies to a scaling matrix: all it does is
stretch or compress the axes.  Likewise, it means that if we leave the
axes alone, we have the normal 3x3 identity matrix:

\begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  0 & 0 & 1 \\
\end{bmatrix}

However, a little effort will reveal that the third transformation we
examined - a translation - cannot be expressed this way.  In short: We
add the extra coordinate (that is, make it [[https://en.wikipedia.org/wiki/Homogeneous_coordinates#Use_in_computer_graphics][homogeneous]]) as a way to
let us express translations in matrix form (and [[https://en.wikipedia.org/wiki/Affine_transformation][affine transformations]]
in general - including the all-important projective transformation
used anytime a 3D render includes perspective).

The transformations given above are rather uninteresting, but
well-studied, well-behaved, efficient to compute, and essential to 3D
graphics in general.

** Rotations

So far we've only shown rotation in the $x$ axis.  It appears
straightforward to extend this rotation in $x$, in $y$, and $z$
(i.e. [[https://en.wikipedia.org/wiki/Euler_angles][Euler angles]]).  The below tries this, illustrating the three
axes with thin rectangles:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "rx",
       "GUIName": "rx"
   },
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "ry",
       "GUIName": "ry"
   },
   {
       "type": "float",
       "value": 0,
       "min": -3.14,
       "max": 3.14,
       "name": "rz",
       "GUIName": "rz"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float rx;
uniform float ry;
uniform float rz;

float distance(in vec3 pos)
{
    mat3 rotx = mat3(1, 0,        0,      
                     0, cos(rx), -sin(rx),
                     0, sin(rx),  cos(rx));
    mat3 roty = mat3(cos(ry), 0, -sin(ry),
                     0,       1, 0,      
                     sin(ry), 0, cos(ry));
    mat3 rotz = mat3(cos(rz), -sin(rz), 0,
                     sin(rz),  cos(rz), 0,
                     0,       0,        1);
    mat3 t = rotx * roty * rotz;

    vec3 offset = vec3(5.0, 0.1, 0.1);
    float x_axis = length(max(abs((pos * t - offset.xyz)) - offset.xyz, 0.0));
    float y_axis = length(max(abs((pos * t - offset.yxz)) - offset.yxz, 0.0));
    float z_axis = length(max(abs((pos * t - offset.yzx)) - offset.yzx, 0.0));
    return min(x_axis, min(y_axis, z_axis));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

(This also demonstrates a WebGL feature called *swizzling*: We may
access a vector's elements in any order, and this is why =y_axis= and
=z_axis= access =offset= as =offset.yxz= and =offset.yzx=,
respectively - it rearranges the coordinates in =offset=.)

However, to see some problems with this, try adjusting the slider for
=ry= to about 1.57 or -1.57 (that is, $\pm\frac{\pi}{2}$), and then
adjust =rx= and =rz=.  No matter how you move the other two, you will
see that they are now moving in the same axis; in effect, you have
lost an axis until you move =ry= to something else.  This is an
illustration of [[https://en.wikipedia.org/wiki/Gimbal_lock][gimbal lock]], and any representation of rotation in 3D
that relies on three angles is susceptible to it.

One alternative to this is [[https://en.wikipedia.org/wiki/Quaternion][quaternions]]:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1,
       "min": -1,
       "max": 1,
       "name": "a_",
       "GUIName": "a"
   },
   {
       "type": "float",
       "value": 0,
       "min": -1,
       "max": 1,
       "name": "b_",
       "GUIName": "b"
   },
   {
       "type": "float",
       "value": 0,
       "min": -1,
       "max": 1,
       "name": "c_",
       "GUIName": "c"
   },
   {
       "type": "float",
       "value": 0,
       "min": -1,
       "max": 1,
       "name": "d_",
       "GUIName": "d"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;
uniform float a_, b_, c_, d_;

float distance(in vec3 pos)
{
    vec4 q = vec4(a_, b_, c_, d_);
    q = q / length(q);

    // Interpolation:
    // q = mix(vec4(1.0, 0.0, 0.0, 0.0), q, sin(time * 0.01) * 0.5 + 0.5);

    float a = q.x, b = q.y, c = q.z, d = q.w;
    mat3 t = mat3(a*a + b*b - c*c - d*d, 2.0*b*c - 2.0*a*d,     2.0*b*d + 2.0*a*c,
                  2.0*b*c + 2.0*a*d,     a*a - b*b + c*c - d*d, 2.0*c*d - 2.0*a*b,
                  2.0*b*d - 2.0*a*c,     2.0*c*d + 2.0*a*b,     a*a - b*b - c*c + d*d);

    vec3 offset = vec3(5.0, 0.1, 0.1);
    float x_axis = length(max(abs((pos * t - offset.xyz)) - offset.xyz, 0.0));
    float y_axis = length(max(abs((pos * t - offset.yxz)) - offset.yxz, 0.0));
    float z_axis = length(max(abs((pos * t - offset.yzx)) - offset.yzx, 0.0));
    return min(x_axis, min(y_axis, z_axis));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(0.0, 0.0, 0.0);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

It is less intuitive than Euler angles, but retains some benefits.  To
see one, uncomment the line below the =// Interpolation= comment in
the =distance()= function, and enable animation; this shows the
ability to linearly interpolate between rotations in two quaternions.

** More on distance functions

*** Primitives

Cubes are likewise rather boring by themselves, even if we can use
matrices to move them around.  However, distance functions can
represent a variety of other shapes.  One very simple one is a sphere:

#+BEGIN_SRC glsl
/* PARAMETERS
[
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;

float distance(in vec3 pos)
{
    return length(pos) - 1.0;
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

See Íñigo Quílez's page [[http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm][Modeling with Distance Functions]] for a list of
many others.

*** Constructive Solid Geometry

Distance functions are also rather easy to combine in the methods of
[[https://en.wikipedia.org/wiki/Constructive_solid_geometry][constructive solid geometry]].  The minimum of two distance functions is
the *union* and the maximum of two is their *intersection*.  Thinking
back to the thought experiment at the start of this chapter, and
considering several different boundaries and several respective GPS
devices, should make it obvious why.

The below code shows the intersection of two spheres; replace =max=
with =min= to instead see their union:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0.1,
       "min": 0,
       "max": 2,
       "name": "offset",
       "GUIName": "Offset"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float offset;

float distance(in vec3 pos)
{
    return max(length(pos + vec3(offset/2.0, 0, 0)) - 1.0,
               length(pos - vec3(offset/2.0, 0, 0)) - 1.0);
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

Negating one of the shapes in a union can also subtract one shape from
another:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1.3,
       "min": 0,
       "max": 2,
       "name": "radius",
       "GUIName": "radius"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float radius;

float distance(in vec3 pos)
{

    return max(-(length(pos) - radius),
               length(max(abs(pos).xyz - 1.0, 0.0)));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

*** Domain warping

The last chapter used modulo in order to warp a function's domain into
an infinitely-repeating space in order to create a grid.  This works
identically here in 3 dimensions, due to the fact that we're working
with a function that maps 3D space to something:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1.3,
       "min": 0,
       "max": 2,
       "name": "radius",
       "GUIName": "radius"
   },
   {
       "type": "float",
       "value": 3,
       "min": 0,
       "max": 6,
       "name": "offset",
       "GUIName": "offset"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float radius;
uniform float offset;

float distance(in vec3 pos)
{
    vec3 pos2 = mod(pos, offset) - offset/2.0;
    return max(-(length(pos2) - radius),
               length(max(abs(pos2).xyz - 1.0, 0.0)));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

This shows one interesting aspect of a sphere tracer: It lets us
represent an infinite amount of geometry without any additional
resource requirements.  Nowhere in here did we have to turn this
geometry into triangles.

We could take this further, and combine it with a rotation.  We could
make this rotation vary by distance from the origin as well.

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 1.3,
       "min": 0,
       "max": 2,
       "name": "radius",
       "GUIName": "radius"
   },
   {
       "type": "float",
       "value": 3,
       "min": 0,
       "max": 6,
       "name": "offset",
       "GUIName": "offset"
   }
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float radius;
uniform float offset;

float distance(in vec3 pos)
{
    float r = length(pos) / 20.0;
    mat3 rot = mat3(cos(r),  0,  sin(r),
                    0,       1,  0,
                    -sin(r), 0,  cos(r));

    vec3 pos2 = mod(pos * rot, offset) - offset/2.0;
    return max(-(length(pos2) - radius),
               length(max(abs(pos2).xyz - 1.0, 0.0)));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

Or, we could add a variable amount of rotation to a cube... that is,
basically twist it like it's flexible:

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0.1,
       "min": -5,
       "max": 5,
       "name": "freq",
       "GUIName": "Freq"
   }   
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

uniform float freq;
uniform float freq2;

float distance(in vec3 pos)
{
    float r = freq * pos.y;
    mat3 rot_y = mat3(cos(r),  0,  sin(r),
                      0,       1,  0,
                      -sin(r), 0,  cos(r));
    return length(max(abs(pos * rot_y).xyz - 1.0, 0.0));
}

void main()
{
    vec2 uv = 2.0 * gl_FragCoord.xy/resolution.xy - 1.0;
    // Correct aspect:
    uv.x = uv.x * resolution.x / resolution.y;

    // Normalize mouse position:
    vec2 m = vec2(mouse.x/resolution.x, 1.0 - mouse.y/resolution.y);
    m.x = m.x * resolution.x / resolution.y;

    // Camera location & target:
    vec3 camera_loc = vec3(-0.5+3.5*cos(6.0*m.x), 1.0 + 2.0*m.y, 0.5 + 4.0*sin(6.0*m.x));
    vec3 camera_target = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation and rendering:
    mat3 ca = setCamera(camera_loc, camera_target, 0.0);
    vec3 rd = ca * normalize(vec3(uv, 2.0));
    vec3 col = render(camera_loc, rd);

    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

** Summary

This concludes the tutorial - at least, until I write more.  The [[./04_Final_Notes.org][next
chapter]] contains some other references that you may wish to read.

# TODO: Mind the goal of this, which is not graphics but math.
