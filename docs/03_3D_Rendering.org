#+Title: 3D Rendering
#+Author: Chris Hodapp

* 3D Rendering

In the last section, we dealt with a class of functions which mapped
2D space (i.e. a pixel location) to color values.  In this section, we
generalize this a bit, and deal with functions that map 3D space to
something.

First, though, consider a (far-fetched) thought experiment.  Suppose
you're outside and you need to trace out some strange geographical
boundary - maybe an irregular, invisible property line.  For whatever
reason, you don't even have a map.  What you do have is a precise but
rather strange GPS device... and all it can do is tell you, whenever
you need, the shortest distance you could move in order to reach the
nearest part of that boundary.  It doesn't tell you which direction.
If it tells you "21 feet", all it means is that in some direction, the
boundary is exactly 21 feet away, and it's not closer than that in any
other direction.

Assume you have some other basic implements, like a tape measure and a
can of spray paint, and assume that you at least know you're starting
somewhere inside this boundary.  Now, how could you go about finding
and marking this boundary (or something fairly close to it)?

There are probably many different answers, but here is one method to
consider:

1. Mark your starting point on the ground.
2. Pick any direction.
3. Get the nearest-distance measurement from the GPS.  Walk in a
   straight line in the chosen direction until you've covered the
   distance the GPS told you.
4. Repeat step 3 using the same direction. Once the GPS gives distance
   measurements that are very small (e.g. one inch), stop.
5. Wherever you are, make a marking on the ground.
6. Return to your starting point.
7. Pick a new direction, rotated very slightly from the last time
   (e.g. just 1/2 degree clockwise).
8. Repeat step 3.  Once you've returned to your starting direction,
   stop.

This is very pain-staking and tedious - but the end result is that
you've marked off the entire boundary, at 1/2 degree increments, to
within an inch. (It's possible you'll miss spots, particularly if it's
a very weird boundary - but you can remedy this by taking more samples
and repeating the process, sometimes from different spots.)

To put it in more technical terms: You just traced out the *distance
surface* that a *distance function* described implicitly. If this
sounds like it's related to the mention of *isolines* in the last
section, it's because it is.

Interestingly enough, the above method still works if the GPS behaves
a little more strangely: it doesn't need to tell you the exact
distance; it could simply tell you some (non-zero) distance for which
you're guaranteed *not* to hit the boundary in any direction.

** Blah blah blah

https://en.wikipedia.org/wiki/Signed_distance_function
vs. signed distance bound.

If $a^2=b$ and \( b=2 \), then the solution must be
either $$ a=+\sqrt{2} $$ or \[ a=-\sqrt{2} \].

\begin{equation}
x=\sqrt{b}
\end{equation}

** Sphere example

#+BEGIN_SRC glsl
/* PARAMETERS
[
   {
       "type": "float",
       "value": 0.1,
       "min": -5,
       "max": 5,
       "name": "freq",
       "GUIName": "Freq"
   },
   {
       "type": "float",
       "value": 0.1,
       "min": -1,
       "max": 1,
       "name": "freq2",
       "GUIName": "Freq2"
   }   
]
END */
#define ENABLE_SPHERE_TRACING

uniform vec2 resolution;
uniform vec4 mouse;
uniform float time;

uniform float freq;
uniform float freq2;

vec2 map(in vec3 pos)
{
    vec3 pos_ = vec3(mod(pos.x, 2.0) - 1.0, pos.y, mod(pos.z, 2.0) - 1.0);
    float ca = cos(freq * pos_.y);
    float sa = sin(freq * pos_.y);
    vec3 pos2 = vec3(pos_.x * ca - pos_.z * sa, pos_.y, pos_.x * sa + pos_.z * ca);
    float ca2 = cos(freq2 * pos2.z);
    float sa2 = sin(freq2 * pos2.z);
    vec3 pos3 = vec3(pos2.x * ca2 - pos2.y * sa2, pos2.x * sa2 + pos2.y * ca2, pos2.z);
    vec2 res = opU(vec2(sdPlane(pos), 1.0),
                   vec2(udRoundBox(pos3-vec3(0.0, 0.5, 0.0), vec3(0.5), 0.05), 7.0));
    return res;
}

void main()
{
    vec2 mo = mouse.xy/resolution.xy;
	float time = 15.0 + time;
    
    vec3 tot = vec3(0.0);
    vec2 p = (-resolution.xy + 2.0*gl_FragCoord.xy)/resolution.y;
    // Camera location:
    vec3 ro = vec3(-0.5+3.5*cos(0.1*time + 6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 4.0*sin(0.1*time + 6.0*mo.x));
    // Camera target:
    vec3 ta = vec3(-0.5, 0.4, 0.5);
    
    // Camera-to-world transformation
    mat3 ca = setCamera(ro, ta, 0.0);
    
    // ray direction
    vec3 rd = ca * normalize(vec3(p.xy, 2.0));

    // render	
    vec3 col = render(ro, rd);

    // gamma
    col = pow(col, vec3(0.4545));
    gl_FragColor = vec4(col, 1.0);
}
#+END_SRC

** Distance Bounds & Distance Fields

*** Why a sphere tracer?

** Transformations

# See "Programming in 3 Dimensions"

*** Scaling

*** Translation

*** Rotation

*** Shearing

*** Vectors & Matrices
# Homogeneous coordinates?
# Composition
# Inverses

** Constructive Solid Geometry

** Domain Warping

** Domain Repetition

** Summary

This concludes the tutorial - at least, until I write more.

I mentioned that distance fields were a sort of extension of what we
looked at in the last section - particularly, of what we can do with
functions that map points in space to something (color, or a distance
bound, for instance).  Another application of this same principle can
be found in the [[https://www.cs.jhu.edu/~subodh/458/p253-perlin.pdf][Hypertexture]] approach of Perlin and Hoffert - in which
a function maps points in 3D space to *density* at that point.

3D rendering is a subject both broad and deep, and this tutorial
covers just a narrow part of one aspect of them.  The next section
gives a handful of references that may be good starting points.

# TODO: Mind the goal of this, which is not graphics but math.
